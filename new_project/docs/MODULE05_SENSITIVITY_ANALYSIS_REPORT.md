# Module05 RQAå‚æ•°æ•æ„Ÿåº¦åˆ†æ - åŠŸèƒ½æŠ¥å‘Š

**æ–‡æ¡£ç‰ˆæœ¬**: v1.0
**åˆ›å»ºæ—¥æœŸ**: 2025-10-10
**ç›®çš„**: ä¸ºModule06ç‰¹å¾é€‰æ‹©æä¾›Module05æ•æ„Ÿåº¦åˆ†æåŠŸèƒ½è¯´æ˜

---

## ğŸ“‹ æ‰§è¡Œæ‘˜è¦

âœ… **å¥½æ¶ˆæ¯**: Module05**å·²ç»å®ç°äº†å®Œæ•´çš„å‚æ•°æ•æ„Ÿåº¦åˆ†æåŠŸèƒ½**!

æ ¸å¿ƒèƒ½åŠ›:
- âœ… è®¡ç®—3264ä¸ªå‚æ•°ç»„åˆçš„æ•æ„Ÿæ€§è¯„åˆ†
- âœ… åŸºäºANOVA F-testè¯„ä¼°ç»„é—´å·®å¼‚
- âœ… è®¡ç®—æ•ˆåº”é‡(Eta-squared)
- âœ… è¯„ä¼°ä»»åŠ¡ä¸€è‡´æ€§
- âœ… ç”Ÿæˆç»¼åˆæ•æ„Ÿåº¦å¾—åˆ†
- âœ… æä¾›å®Œæ•´çš„APIæ¥å£å’Œå¯è§†åŒ–

---

## 1. å·²å®ç°çš„æ•æ„Ÿåº¦åˆ†æåŠŸèƒ½

### 1.1 æ ¸å¿ƒåˆ†æå™¨

**æ–‡ä»¶**: `parameter_sensitivity_analyzer.py`

**åŠŸèƒ½**: è®¡ç®—æ¯ä¸ªRQAå‚æ•°ç»„åˆåœ¨åŒºåˆ†Control/MCI/ADä¸‰ç»„é—´çš„èƒ½åŠ›

### 1.2 åˆ†ææŒ‡æ ‡ (5ä¸ª)

Module05çš„æ•æ„Ÿåº¦åˆ†æä½¿ç”¨**5ä¸ªäº’è¡¥æŒ‡æ ‡**:

#### æŒ‡æ ‡1: F-statistic (ANOVA)
```python
# å¯¹æ¯ä¸ªä»»åŠ¡(q1-q5)åˆ†åˆ«è®¡ç®—ANOVA Fç»Ÿè®¡é‡
for task in ['q1', 'q2', 'q3', 'q4', 'q5']:
    control = df[df['group'] == 'control'][feature]
    mci = df[df['group'] == 'mci'][feature]
    ad = df[df['group'] == 'ad'][feature]

    f_stat, p_val = stats.f_oneway(control, mci, ad)
```
**å«ä¹‰**: ç»„é—´å·®å¼‚ vs ç»„å†…å·®å¼‚æ¯”å€¼,è¶Šå¤§è¶Šå¥½

#### æŒ‡æ ‡2: P-value
```python
# ANOVAè¿”å›çš„æ˜¾è‘—æ€§på€¼
# p < 0.05 è¡¨ç¤ºç»Ÿè®¡æ˜¾è‘—
```
**å«ä¹‰**: ç»Ÿè®¡æ˜¾è‘—æ€§,è¶Šå°è¶Šå¥½

#### æŒ‡æ ‡3: Effect Size (Eta-squared)
```python
# è®¡ç®—æ•ˆåº”é‡
eta_squared = SS_between / SS_total
```
**å«ä¹‰**: ç»„åˆ«å› ç´ è§£é‡Šçš„æ–¹å·®æ¯”ä¾‹ (0-1),è¶Šå¤§æ•ˆåº”è¶Šå¼º
- 0.01-0.06: å°æ•ˆåº”
- 0.06-0.14: ä¸­ç­‰æ•ˆåº”
- 0.14+: å¤§æ•ˆåº”

#### æŒ‡æ ‡4: Task Consistency (ä»»åŠ¡ä¸€è‡´æ€§)
```python
# è·¨ä»»åŠ¡çš„Fç»Ÿè®¡é‡å˜å¼‚ç³»æ•°
cv = std(f_stats) / mean(f_stats)
task_consistency = 1 / (1 + cv)  # å½’ä¸€åŒ–åˆ°[0,1]
```
**å«ä¹‰**: å‚æ•°åœ¨ä¸åŒä»»åŠ¡ä¸Šè¡¨ç°çš„ç¨³å®šæ€§,è¶Šé«˜è¶Šå¥½

#### æŒ‡æ ‡5: Overall Score (ç»¼åˆè¯„åˆ†)
```python
overall_score = (
    0.4 * min(f_stat_mean / 100, 1.0) +  # Fç»Ÿè®¡é‡æƒé‡40%
    0.3 * effect_size_mean +              # æ•ˆåº”é‡æƒé‡30%
    0.2 * task_consistency -              # ä¸€è‡´æ€§æƒé‡20%
    0.1 * p_val_mean                      # på€¼æƒ©ç½š10%
)
```
**å«ä¹‰**: åŠ æƒç»¼åˆå¾—åˆ†,ç”¨äºæ’åº

---

## 2. APIæ¥å£

### 2.1 æ ¸å¿ƒAPIç«¯ç‚¹

#### API #1: æ‰«æRQAç»“æœ
```
GET /api/m05/sensitivity/scan-results
```
**åŠŸèƒ½**: æ‰«æç£ç›˜ä¸Šæ‰€æœ‰å·²å®Œæˆçš„RQAåˆ†æç»“æœ

**å“åº”ç¤ºä¾‹**:
```json
{
    "success": true,
    "results": [
        {
            "params": {"m": 2, "tau": 1, "eps": 0.050, "lmin": 2},
            "enriched_features_path": "data/05_rqa_analysis/m2_tau1_eps0.050_lmin2/step3_enriched_features.csv"
        },
        ...
    ],
    "total": 3264
}
```

#### API #2: è®¡ç®—æ•æ„Ÿåº¦è¯„åˆ† (å¼‚æ­¥ä»»åŠ¡)
```
POST /api/m05/sensitivity/compute-scores
{
    "params_filter": {
        "m_range": [1, 10],
        "tau_range": [1, 10]
    }
}
```
**åŠŸèƒ½**: æäº¤æ•æ„Ÿåº¦åˆ†æä»»åŠ¡(å¼‚æ­¥æ‰§è¡Œ,é¿å…é˜»å¡)

**å“åº”**:
```json
{
    "success": true,
    "task_id": "sensitivity_task_20251010_143052",
    "message": "å‚æ•°æ•æ„Ÿæ€§åˆ†æä»»åŠ¡å·²æäº¤"
}
```

#### API #3: æŸ¥è¯¢ä»»åŠ¡çŠ¶æ€
```
GET /api/m05/sensitivity/status/<task_id>
```
**å“åº”ç¤ºä¾‹**:
```json
{
    "success": true,
    "data": {
        "task": {
            "task_id": "sensitivity_task_20251010_143052",
            "status": "completed",  // pending, running, completed, failed
            "progress": 100,
            "total_params": 3264,
            "processed_params": 3264,
            "result_file": "data/05_rqa_analysis/sensitivity_scores_20251010_143052.csv"
        }
    }
}
```

#### API #4: 3Då‚æ•°ç©ºé—´å¯è§†åŒ–
```
POST /api/m05/sensitivity/plot-3d-space
{
    "feature": "rr-1d-x",
    "sensitivity_scores_file": "sensitivity_scores.csv"
}
```
**åŠŸèƒ½**: ç”Ÿæˆäº¤äº’å¼3Dæ•£ç‚¹å›¾(Plotly)

#### API #5: å‚æ•°-ç‰¹å¾çƒ­å›¾
```
POST /api/m05/sensitivity/plot-heatmap
{
    "sensitivity_scores_file": "sensitivity_scores.csv",
    "metric": "overall_score"
}
```
**åŠŸèƒ½**: ç”Ÿæˆå‚æ•°ç»„åˆ Ã— RQAç‰¹å¾çƒ­å›¾

---

## 3. RQAç‰¹å¾ç»´åº¦

### 3.1 åŠ¨æ€ç‰¹å¾è¯†åˆ«

Module05ä½¿ç”¨`_identify_rqa_features()`è‡ªåŠ¨è¯†åˆ«RQAç‰¹å¾åˆ—:

**è¯†åˆ«æ¨¡å¼**:
```python
rqa_prefixes = ['rr-', 'det-', 'ent-', 'lam-', 'x_', 'y_', 'combined_', 'rqa_']
rqa_keywords = ['symmetry', 'diff', 'complexity']
```

**å®é™…ç‰¹å¾åˆ—** (åŸºäºstep3_enriched_features.csv):
```
1Dç‰¹å¾ (xåæ ‡):
- rr-1d-x       # é€’å½’ç‡
- det-1d-x      # ç¡®å®šæ€§
- ent-1d-x      # ç†µ
- lam-1d-x      # Laminarity

1Dç‰¹å¾ (yåæ ‡):
- rr-1d-y
- det-1d-y
- ent-1d-y
- lam-1d-y

2Dç‰¹å¾ (xyè½¨è¿¹):
- rr-2d-xy
- det-2d-xy
- ent-2d-xy
- lam-2d-xy

æ´¾ç”Ÿç‰¹å¾:
- combined_rr
- rqa_complexity_1d
- rqa_complexity_2d
- x_y_symmetry
- rr_xy_diff
- det_xy_diff
...
```

**æ€»è®¡**: çº¦**15-20ä¸ªRQAç‰¹å¾** (å–å†³äºstep3å¢å¼ºé€»è¾‘)

---

## 4. Module06é›†æˆæ–¹æ¡ˆ

### 4.1 ç­–ç•¥A: é€‰æ‹©Top-6 RQAç‰¹å¾

**æ–¹æ³•1**: åŸºäºå•ä¸ªæœ€ä¼˜å‚æ•°
```python
# Step 1: è·å–æ•æ„Ÿåº¦è¯„åˆ†
response = requests.get('/api/m05/sensitivity/compute-scores')
task_id = response.json()['task_id']

# Step 2: ç­‰å¾…å®Œæˆ
while True:
    status = requests.get(f'/api/m05/sensitivity/status/{task_id}').json()
    if status['data']['task']['status'] == 'completed':
        break

# Step 3: è¯»å–ç»“æœ
result_file = status['data']['task']['result_file']
sensitivity_df = pd.read_csv(result_file)

# Step 4: é€‰æ‹©overall_scoreæœ€é«˜çš„å‚æ•°ç»„åˆ
best_param = sensitivity_df.groupby('param_signature').agg({
    'overall_score': 'mean'
}).idxmax()

# Step 5: æå–è¯¥å‚æ•°ä¸‹Top-6 RQAç‰¹å¾
param_features = sensitivity_df[
    sensitivity_df['param_signature'] == best_param
].sort_values('overall_score', ascending=False).head(6)

top6_features = param_features['feature'].tolist()
# ä¾‹å¦‚: ['rr-2d-xy', 'det-2d-xy', 'ent-1d-x', 'rr-1d-x', 'det-1d-x', 'ent-2d-xy']
```

**æ–¹æ³•2**: è·¨å‚æ•°é€‰æ‹©Top-6ç‰¹å¾ (æ¨è)
```python
# å¯¹æ‰€æœ‰å‚æ•°ç»„åˆ,æŒ‰ç‰¹å¾èšåˆæ•æ„Ÿåº¦
feature_scores = sensitivity_df.groupby('feature').agg({
    'overall_score': 'mean',
    'f_statistic': 'mean',
    'effect_size': 'mean'
}).sort_values('overall_score', ascending=False)

top6_features = feature_scores.head(6).index.tolist()
```

### 4.2 ç­–ç•¥B: é€‰æ‹©Top-10å‚æ•°ç»„åˆ

```python
# æŒ‰å‚æ•°ç»„åˆèšåˆ
param_scores = sensitivity_df.groupby('param_signature').agg({
    'overall_score': 'mean',
    'f_statistic': 'mean',
    'effect_size': 'mean',
    'task_consistency': 'mean'
}).sort_values('overall_score', ascending=False)

top10_params = param_scores.head(10).index.tolist()

# æ¯ä¸ªå‚æ•°æå–6ç»´RQAç‰¹å¾
# æ€»è®¡: 10 Ã— 6 = 60ç»´
```

---

## 5. å…³é”®é—®é¢˜åˆ†æ

### 5.1 âœ… Module05å·²ç»æ‰¾å‡ºæœ€æ•æ„Ÿçš„ç‰¹å¾å—?

**ç­”**: **éƒ¨åˆ†å®Œæˆ,ä½†éœ€è¦è¿è¡Œè®¡ç®—**

- âœ… **æ•æ„Ÿåº¦åˆ†æåŠŸèƒ½å·²å®ç°**: `ParameterSensitivityAnalyzer`ç±»å®Œæ•´å®ç°
- âœ… **APIç«¯ç‚¹å¯ç”¨**: `/api/m05/sensitivity/compute-scores`
- â“ **æ˜¯å¦å·²è¿è¡Œè¿‡**: éœ€è¦æ£€æŸ¥æ˜¯å¦æœ‰ç¼“å­˜çš„æ•æ„Ÿåº¦è¯„åˆ†æ–‡ä»¶

è®©æˆ‘æ£€æŸ¥æ˜¯å¦æœ‰ç¼“å­˜ç»“æœ:

```bash
# æ£€æŸ¥æ˜¯å¦æœ‰æ•æ„Ÿåº¦è¯„åˆ†æ–‡ä»¶
ls data/05_rqa_analysis/sensitivity_scores_*.csv
```

### 5.2 æ•æ„Ÿåº¦åˆ†æçš„è®¡ç®—æˆæœ¬

**è¾“å…¥**: 3264ä¸ªå‚æ•°ç»„åˆ Ã— 5ä¸ªä»»åŠ¡ Ã— ~15ä¸ªRQAç‰¹å¾ = **çº¦245,000æ¬¡ANOVAè®¡ç®—**

**é¢„è®¡æ—¶é—´**:
- CPUå¯†é›†å‹è®¡ç®—
- é¢„è®¡è€—æ—¶: 10-30åˆ†é’Ÿ (å–å†³äºCPUæ€§èƒ½)
- å†…å­˜éœ€æ±‚: ~2GB

**å»ºè®®**:
- æäº¤å¼‚æ­¥ä»»åŠ¡,ä¸è¦é˜»å¡ä¸»çº¿ç¨‹
- ç»“æœç¼“å­˜åˆ°CSV,é¿å…é‡å¤è®¡ç®—

---

## 6. Module06ä½¿ç”¨å»ºè®®

### 6.1 ç­–ç•¥Aå®æ–½æ­¥éª¤

**Step 1**: è¿è¡ŒModule05æ•æ„Ÿåº¦åˆ†æ(å¦‚æœæœªè¿è¡Œ)
```bash
curl -X POST http://127.0.0.1:9090/api/m05/sensitivity/compute-scores
```

**Step 2**: ç­‰å¾…å®Œæˆ,è·å–ç»“æœ
```bash
curl http://127.0.0.1:9090/api/m05/sensitivity/status/<task_id>
```

**Step 3**: ä»ç»“æœä¸­é€‰æ‹©Top-6 RQAç‰¹å¾
```python
# æ–¹æ³•1: å•ä¸ªæœ€ä¼˜å‚æ•°çš„6ç»´
# æ–¹æ³•2: è·¨å‚æ•°Top-6ç‰¹å¾
```

**Step 4**: Module04é€‰æ‹©Top-4,Module05é€‰æ‹©Top-6
```python
# æ€»è®¡: 4 + 6 = 10ç»´
# æ ·æœ¬æ¯”: 300 / 10 = 30:1 âœ…
```

### 6.2 ç‰¹å¾é€‰æ‹©æ–¹æ³•å¯¹æ¯”

| æ–¹æ³• | Module04 | Module05 | æ€»ç»´åº¦ | æ ·æœ¬æ¯” | ä¼˜åŠ¿ |
|------|----------|----------|--------|--------|------|
| **A1** | Top-4ç‰¹å¾ | å•å‚æ•°6ç»´RQA | 10ç»´ | 30:1 | æç®€,å¯è§£é‡Šæ€§å¼º |
| **A2** | Top-4ç‰¹å¾ | è·¨å‚æ•°Top-6ç‰¹å¾ | 10ç»´ | 30:1 | ç‰¹å¾å¤šæ ·æ€§é«˜ |
| **B** | å…¨é‡9ç»´ | Top-10å‚æ•°Ã—6 | 69ç»´ | 4.3:1 | ç‰¹å¾å®Œæ•´,æ€§èƒ½é«˜ |

**æ¨è**: **æ–¹æ³•A2** - è·¨å‚æ•°é€‰æ‹©Top-6 RQAç‰¹å¾
- åŸå› : ä¸åŒå‚æ•°ç»„åˆå¯èƒ½åœ¨ä¸åŒç‰¹å¾ä¸Šè¡¨ç°æœ€ä½³,è·¨å‚æ•°é€‰æ‹©é¿å…å±€é™äºå•ä¸€å‚æ•°ç»„åˆ

---

## 7. å¾…åŠäº‹é¡¹

**Module05ä¾§**:
- [ ] è¿è¡Œæ•æ„Ÿåº¦åˆ†æ(å¦‚æœæœªè¿è¡Œ)
- [ ] ç¡®è®¤ç¼“å­˜ç»“æœå¯ç”¨
- [ ] å¯é€‰: æ·»åŠ APIè¿”å›Top-Kç‰¹å¾ç›´æ¥æŸ¥è¯¢æ¥å£

**Module06ä¾§**:
- [ ] é›†æˆModule05æ•æ„Ÿåº¦API
- [ ] å®ç°Top-6ç‰¹å¾é€‰æ‹©é€»è¾‘
- [ ] ä¸Module04 Top-4ç‰¹å¾èåˆ
- [ ] ç”Ÿæˆ10ç»´ç‰¹å¾å‘é‡

---

## 8. æ€»ç»“

### âœ… Module05å·²å…·å¤‡çš„èƒ½åŠ›

1. **å®Œæ•´çš„å‚æ•°æ•æ„Ÿåº¦åˆ†æå™¨**: 5ä¸ªäº’è¡¥æŒ‡æ ‡
2. **APIæ¥å£**: å¼‚æ­¥ä»»åŠ¡æäº¤ã€çŠ¶æ€æŸ¥è¯¢
3. **å¯è§†åŒ–æ”¯æŒ**: 3Då‚æ•°ç©ºé—´ã€çƒ­å›¾
4. **åŠ¨æ€ç‰¹å¾è¯†åˆ«**: è‡ªé€‚åº”RQAç‰¹å¾åˆ—

### âš ï¸ éœ€è¦ç¡®è®¤çš„äº‹é¡¹

1. **æ˜¯å¦å·²è¿è¡Œè¿‡æ•æ„Ÿåº¦åˆ†æ**: æ£€æŸ¥ç¼“å­˜æ–‡ä»¶
2. **RQAç‰¹å¾å®é™…æ•°é‡**: å–å†³äºstep3å¢å¼ºé€»è¾‘
3. **æœ€ä¼˜å‚æ•°ç»„åˆ**: éœ€è¦æŸ¥çœ‹å®é™…è¯„åˆ†ç»“æœ

### ğŸ¯ ä¸‹ä¸€æ­¥è¡ŒåŠ¨

**ä¼˜å…ˆçº§1**: æ£€æŸ¥æ˜¯å¦æœ‰æ•æ„Ÿåº¦è¯„åˆ†ç¼“å­˜
```bash
ls -lh data/05_rqa_analysis/sensitivity_scores_*.csv
```

**ä¼˜å…ˆçº§2**: å¦‚æœæ²¡æœ‰,è¿è¡Œæ•æ„Ÿåº¦åˆ†æ
```bash
curl -X POST http://127.0.0.1:9090/api/m05/sensitivity/compute-scores
```

**ä¼˜å…ˆçº§3**: æŸ¥çœ‹Top-10å‚æ•°å’ŒTop-6ç‰¹å¾
```python
sensitivity_df = pd.read_csv('sensitivity_scores.csv')
print(sensitivity_df.groupby('param_signature')['overall_score'].mean().sort_values(ascending=False).head(10))
print(sensitivity_df.groupby('feature')['overall_score'].mean().sort_values(ascending=False).head(6))
```

---

**æ–‡æ¡£çŠ¶æ€**: âœ… å®Œæˆ
**å®¡æ ¸çŠ¶æ€**: å¾…éªŒè¯ç¼“å­˜æ–‡ä»¶
**ä¸‹ä¸€æ­¥**: è¿è¡Œæ•æ„Ÿåº¦åˆ†ææˆ–æŸ¥çœ‹ç¼“å­˜ç»“æœ
