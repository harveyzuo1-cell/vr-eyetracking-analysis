# Module06 æ··åˆç‰¹å¾é€‰æ‹©æ–¹æ¡ˆï¼ˆæ–¹æ¡ˆCï¼‰è®¾è®¡æ–‡æ¡£

## ğŸ“‹ ç›®å½•
1. [è®¾è®¡ç›®æ ‡](#1-è®¾è®¡ç›®æ ‡)
2. [æ•´ä½“æ¶æ„](#2-æ•´ä½“æ¶æ„)
3. [æŠ€æœ¯åŸç†](#3-æŠ€æœ¯åŸç†)
4. [åç«¯è®¾è®¡](#4-åç«¯è®¾è®¡)
5. [å‰ç«¯è®¾è®¡](#5-å‰ç«¯è®¾è®¡)
6. [APIæ¥å£è®¾è®¡](#6-apiæ¥å£è®¾è®¡)
7. [æ•°æ®æµç¨‹](#7-æ•°æ®æµç¨‹)
8. [å®æ–½æ­¥éª¤](#8-å®æ–½æ­¥éª¤)
9. [æµ‹è¯•éªŒè¯](#9-æµ‹è¯•éªŒè¯)

---

## 1. è®¾è®¡ç›®æ ‡

### 1.1 å½“å‰é—®é¢˜
- **ç›®æ ‡ä¸ä¸€è‡´**ï¼šæ•æ„Ÿåº¦åˆ†æä¼˜åŒ–"åˆ†ç»„åŒºåˆ†èƒ½åŠ›"ï¼Œä½†æœ€ç»ˆä»»åŠ¡æ˜¯"MMSEå›å½’é¢„æµ‹"
- **å•å˜é‡åˆ†æ**ï¼šæœªè€ƒè™‘ç‰¹å¾é—´äº¤äº’å’Œå†—ä½™
- **ç¼ºå°‘éªŒè¯**ï¼šæœªè¯„ä¼°é€‰å‡ºçš„ç‰¹å¾åœ¨MLPä»»åŠ¡ä¸­çš„å®é™…æ€§èƒ½

### 1.2 ä¼˜åŒ–ç›®æ ‡
- âœ… **ä¸‰é˜¶æ®µæ··åˆæ–¹æ³•**ï¼šFilterå¿«é€Ÿé¢„ç­›é€‰ â†’ å›å½’éªŒè¯ â†’ Wrapperç²¾é€‰
- âœ… **é’ˆå¯¹å›å½’ä»»åŠ¡ä¼˜åŒ–**ï¼šä½¿ç”¨ä¸MMSEç›¸å…³æ€§ã€äº’ä¿¡æ¯ã€MLPæ€§èƒ½ä½œä¸ºè¯„ä¼°æŒ‡æ ‡
- âœ… **å¯è§†åŒ–å¯¹æ¯”**ï¼šå±•ç¤ºä¸åŒæ–¹æ³•çš„ç‰¹å¾é‡è¦æ€§å’Œæ€§èƒ½å·®å¼‚
- âœ… **ç”¨æˆ·å¯é€‰**ï¼šæ”¯æŒ"å¿«é€Ÿæ¨¡å¼"ï¼ˆå½“å‰ANOVAï¼‰å’Œ"ç²¾ç¡®æ¨¡å¼"ï¼ˆæ··åˆæ–¹æ³•ï¼‰

---

## 2. æ•´ä½“æ¶æ„

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        Module06 æ··åˆç‰¹å¾é€‰æ‹©                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

é˜¶æ®µ1: Filteré¢„ç­›é€‰ (60ç§’)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  27ä¸ªå€™é€‰ç‰¹å¾ (9ä¸ªM04 + 18ä¸ªM05)                      â”‚
â”‚  â†“                                                    â”‚
â”‚  æ–¹æ³•1: ANOVAæ•æ„Ÿåº¦åˆ†æ (å½“å‰)                        â”‚
â”‚  æ–¹æ³•2: F-regression (å›å½’Fç»Ÿè®¡é‡)                    â”‚
â”‚  æ–¹æ³•3: Mutual Information (äº’ä¿¡æ¯)                   â”‚
â”‚  â†“                                                    â”‚
â”‚  ä¸‰ç§æ–¹æ³•æŠ•ç¥¨ â†’ ç­›é€‰åˆ° Top-15 å€™é€‰                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â†“
é˜¶æ®µ2: å›å½’éªŒè¯ (30ç§’)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  15ä¸ªå€™é€‰ç‰¹å¾                                         â”‚
â”‚  â†“                                                    â”‚
â”‚  1. è®¡ç®—ä¸MMSEçš„Pearson/Spearmanç›¸å…³ç³»æ•°             â”‚
â”‚  2. ç§»é™¤ä½ç›¸å…³ç‰¹å¾ (|r| < 0.25)                      â”‚
â”‚  3. æ£€æŸ¥å¤šé‡å…±çº¿æ€§ (VIF < 5)                         â”‚
â”‚  â†“                                                    â”‚
â”‚  ä¿ç•™ 12-13ä¸ªç‰¹å¾                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â†“
é˜¶æ®µ3: Wrapperç²¾é€‰ (5-10åˆ†é’Ÿ)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  12-13ä¸ªå€™é€‰ç‰¹å¾                                      â”‚
â”‚  â†“                                                    â”‚
â”‚  æ–¹æ³•A: RFE + MLP (é€’å½’ç‰¹å¾æ¶ˆé™¤)                      â”‚
â”‚  æ–¹æ³•B: LassoCV (L1æ­£åˆ™åŒ–)                            â”‚
â”‚  æ–¹æ³•C: Random Forest Feature Importance              â”‚
â”‚  â†“                                                    â”‚
â”‚  äº¤å‰éªŒè¯è¯„ä¼° â†’ é€‰å‡º Top-10                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â†“
              æœ€ç»ˆç‰¹å¾é›† (10ç»´)
```

---

## 3. æŠ€æœ¯åŸç†

### 3.1 é˜¶æ®µ1ï¼šFilteré¢„ç­›é€‰

#### **æ–¹æ³•1: ANOVA F-statisticï¼ˆå½“å‰ï¼‰**
```python
# ç»„é—´å·®å¼‚æ£€éªŒ
F = MS_between / MS_within
Score = (F Ã— Î·Â²) / (1 + p) Ã— (1 / (1 + CV/100))
```
- **ä¼˜ç‚¹**ï¼šå¿«é€Ÿã€å¯è§£é‡Šæ€§å¼º
- **ç¼ºç‚¹**ï¼šé’ˆå¯¹åˆ†ç±»ä»»åŠ¡ä¼˜åŒ–

#### **æ–¹æ³•2: F-regression**
```python
from sklearn.feature_selection import f_regression

# å›å½’Fç»Ÿè®¡é‡ï¼ˆå‡è®¾çº¿æ€§å…³ç³»ï¼‰
F_scores, p_values = f_regression(X_features, y_mmse)

# è®¡åˆ†å…¬å¼
Score = F / (1 + p_value)
```
- **ä¼˜ç‚¹**ï¼šç›´æ¥é’ˆå¯¹è¿ç»­ç›®æ ‡å˜é‡
- **å‡è®¾**ï¼šç‰¹å¾ä¸MMSEçº¿æ€§ç›¸å…³

#### **æ–¹æ³•3: Mutual Information**
```python
from sklearn.feature_selection import mutual_info_regression

# äº’ä¿¡æ¯ï¼ˆå¯æ•æ‰éçº¿æ€§ï¼‰
MI_scores = mutual_info_regression(X_features, y_mmse, random_state=42)
```
- **ä¼˜ç‚¹**ï¼šå¯æ•æ‰éçº¿æ€§å…³ç³»
- **ç¼ºç‚¹**ï¼šè®¡ç®—æ…¢ï¼Œéœ€è¦è°ƒå‚

#### **æŠ•ç¥¨ç­–ç•¥**
```python
# æ ‡å‡†åŒ–ä¸‰ç§æ–¹æ³•çš„å¾—åˆ†
rank_anova = rankdata(-scores_anova)
rank_freg = rankdata(-scores_freg)
rank_mi = rankdata(-scores_mi)

# Borda CountæŠ•ç¥¨
combined_rank = rank_anova + rank_freg + rank_mi

# é€‰æ‹©Top-15
top_15_features = features[np.argsort(combined_rank)[:15]]
```

---

### 3.2 é˜¶æ®µ2ï¼šå›å½’éªŒè¯

#### **ç›¸å…³æ€§åˆ†æ**
```python
from scipy.stats import pearsonr, spearmanr

for feature in top_15_features:
    r_pearson, p_pearson = pearsonr(X[feature], y_mmse)
    r_spearman, p_spearman = spearmanr(X[feature], y_mmse)

    # è¿‡æ»¤ä½ç›¸å…³ç‰¹å¾
    if abs(r_pearson) < 0.25 and abs(r_spearman) < 0.25:
        remove_feature(feature)
```

**ç›¸å…³ç³»æ•°è§£é‡Šï¼š**
- |r| â‰¥ 0.5ï¼šå¼ºç›¸å…³ â­â­â­
- 0.3 â‰¤ |r| < 0.5ï¼šä¸­ç­‰ç›¸å…³ â­â­
- 0.1 â‰¤ |r| < 0.3ï¼šå¼±ç›¸å…³ â­
- |r| < 0.1ï¼šå‡ ä¹æ— å…³ âŒ

#### **å¤šé‡å…±çº¿æ€§æ£€æŸ¥ï¼ˆVIFï¼‰**
```python
from statsmodels.stats.outliers_influence import variance_inflation_factor

# è®¡ç®—æ–¹å·®è†¨èƒ€å› å­
vif_data = pd.DataFrame()
vif_data["feature"] = features
vif_data["VIF"] = [variance_inflation_factor(X.values, i)
                   for i in range(len(features))]

# ç§»é™¤VIF > 5çš„ç‰¹å¾ï¼ˆé«˜å…±çº¿æ€§ï¼‰
features_filtered = vif_data[vif_data["VIF"] < 5]["feature"].tolist()
```

**VIFè§£é‡Šï¼š**
- VIF < 5ï¼šå¯æ¥å— âœ…
- 5 â‰¤ VIF < 10ï¼šä¸­ç­‰å…±çº¿æ€§ âš ï¸
- VIF â‰¥ 10ï¼šä¸¥é‡å…±çº¿æ€§ï¼Œéœ€ç§»é™¤ âŒ

---

### 3.3 é˜¶æ®µ3ï¼šWrapperç²¾é€‰

#### **æ–¹æ³•A: RFE + MLP**
```python
from sklearn.feature_selection import RFE
from sklearn.neural_network import MLPRegressor

mlp = MLPRegressor(
    hidden_layer_sizes=(64, 32, 16),
    activation='relu',
    max_iter=1000,
    random_state=42
)

# é€’å½’ç‰¹å¾æ¶ˆé™¤
rfe = RFE(estimator=mlp, n_features_to_select=10, step=1)
rfe.fit(X_train, y_train)

selected_features = rfe.support_
```

**åŸç†ï¼š**
1. è®­ç»ƒæ¨¡å‹ï¼Œè®¡ç®—ç‰¹å¾é‡è¦æ€§
2. ç§»é™¤æœ€ä¸é‡è¦çš„ç‰¹å¾
3. é‡å¤ç›´åˆ°å‰©ä½™10ä¸ªç‰¹å¾

#### **æ–¹æ³•B: LassoCV**
```python
from sklearn.linear_model import LassoCV

lasso = LassoCV(cv=5, random_state=42, max_iter=10000)
lasso.fit(X_train, y_train)

# L1æ­£åˆ™åŒ–è‡ªåŠ¨ç‰¹å¾é€‰æ‹©
feature_importance = np.abs(lasso.coef_)
top_10_indices = np.argsort(feature_importance)[-10:]
```

**åŸç†ï¼š** L1æƒ©ç½šå°†ä¸é‡è¦ç‰¹å¾çš„ç³»æ•°å‹ç¼©ä¸º0

#### **æ–¹æ³•C: Random Forest**
```python
from sklearn.ensemble import RandomForestRegressor

rf = RandomForestRegressor(n_estimators=200, max_depth=10, random_state=42)
rf.fit(X_train, y_train)

feature_importance = rf.feature_importances_
top_10_indices = np.argsort(feature_importance)[-10:]
```

#### **äº¤å‰éªŒè¯è¯„ä¼°**
```python
from sklearn.model_selection import cross_val_score

# å¯¹æ¯ä¸ªæ–¹æ³•çš„ç‰¹å¾å­é›†è¿›è¡Œ5æŠ˜äº¤å‰éªŒè¯
for method in ['RFE', 'Lasso', 'RF']:
    features_subset = selected_features[method]

    scores = cross_val_score(
        mlp, X[:, features_subset], y_mmse,
        cv=5, scoring='r2'
    )

    print(f"{method}: RÂ² = {scores.mean():.3f} Â± {scores.std():.3f}")

# é€‰æ‹©RÂ²æœ€é«˜çš„æ–¹æ³•
best_method = max(methods, key=lambda m: m['r2_mean'])
```

---

## 4. åç«¯è®¾è®¡

### 4.1 æ–°å¢æ¨¡å—ç»“æ„

```
src/modules/module06_feature_extraction/
â”œâ”€â”€ hybrid_selector.py           # æ··åˆç‰¹å¾é€‰æ‹©å™¨ï¼ˆæ–°å¢ï¼‰
â”œâ”€â”€ filter_methods.py            # Filteræ–¹æ³•é›†åˆï¼ˆæ–°å¢ï¼‰
â”œâ”€â”€ wrapper_methods.py           # Wrapperæ–¹æ³•é›†åˆï¼ˆæ–°å¢ï¼‰
â”œâ”€â”€ validation_utils.py          # éªŒè¯å·¥å…·ï¼ˆæ–°å¢ï¼‰
â”œâ”€â”€ service.py                   # æœåŠ¡å±‚ï¼ˆæ‰©å±•ï¼‰
â””â”€â”€ api.py                       # APIè·¯ç”±ï¼ˆæ‰©å±•ï¼‰
```

---

### 4.2 æ ¸å¿ƒç±»è®¾è®¡

#### **4.2.1 HybridFeatureSelectorï¼ˆæ··åˆé€‰æ‹©å™¨ï¼‰**

```python
# hybrid_selector.py

import numpy as np
import pandas as pd
from typing import Dict, List, Tuple
from sklearn.model_selection import cross_val_score
from sklearn.neural_network import MLPRegressor

from .filter_methods import FilterMethods
from .wrapper_methods import WrapperMethods
from .validation_utils import ValidationUtils


class HybridFeatureSelector:
    """
    æ··åˆç‰¹å¾é€‰æ‹©å™¨ï¼ˆä¸‰é˜¶æ®µï¼‰

    é˜¶æ®µ1: Filteré¢„ç­›é€‰ï¼ˆANOVA + F-regression + MIï¼‰
    é˜¶æ®µ2: å›å½’éªŒè¯ï¼ˆç›¸å…³æ€§ + VIFï¼‰
    é˜¶æ®µ3: Wrapperç²¾é€‰ï¼ˆRFE + Lasso + RFï¼‰
    """

    def __init__(self, X: pd.DataFrame, y: pd.Series,
                 feature_names: List[str], groups: pd.Series = None):
        """
        åˆå§‹åŒ–æ··åˆé€‰æ‹©å™¨

        Args:
            X: ç‰¹å¾çŸ©é˜µ (n_samples, n_features)
            y: ç›®æ ‡å˜é‡ï¼ˆMMSEåˆ†æ•°ï¼‰
            feature_names: ç‰¹å¾åç§°åˆ—è¡¨
            groups: åˆ†ç»„æ ‡ç­¾ï¼ˆç”¨äºANOVAï¼‰
        """
        self.X = X
        self.y = y
        self.feature_names = feature_names
        self.groups = groups

        self.filter = FilterMethods(X, y, feature_names, groups)
        self.wrapper = WrapperMethods(X, y, feature_names)
        self.validator = ValidationUtils(X, y, feature_names)

        # å­˜å‚¨æ¯é˜¶æ®µç»“æœ
        self.stage1_results = None
        self.stage2_results = None
        self.stage3_results = None

    def run_stage1_filter(self, top_k: int = 15) -> Dict:
        """
        é˜¶æ®µ1: Filteré¢„ç­›é€‰

        Returns:
            {
                'anova_scores': [...],
                'freg_scores': [...],
                'mi_scores': [...],
                'combined_ranks': [...],
                'top_features': [...],
                'execution_time': 60.5
            }
        """
        import time
        start_time = time.time()

        # 1. ANOVAæ•æ„Ÿåº¦åˆ†æ
        anova_scores = self.filter.compute_anova_scores()

        # 2. F-regression
        freg_scores = self.filter.compute_f_regression_scores()

        # 3. Mutual Information
        mi_scores = self.filter.compute_mutual_info_scores()

        # 4. Borda CountæŠ•ç¥¨
        combined_ranks = self.filter.combine_ranks(
            anova_scores, freg_scores, mi_scores
        )

        # 5. é€‰æ‹©Top-K
        top_indices = np.argsort(combined_ranks)[:top_k]
        top_features = [self.feature_names[i] for i in top_indices]

        self.stage1_results = {
            'anova_scores': anova_scores,
            'freg_scores': freg_scores,
            'mi_scores': mi_scores,
            'combined_ranks': combined_ranks,
            'top_features': top_features,
            'top_indices': top_indices,
            'execution_time': time.time() - start_time
        }

        return self.stage1_results

    def run_stage2_validation(self, threshold_corr: float = 0.25,
                              threshold_vif: float = 5.0) -> Dict:
        """
        é˜¶æ®µ2: å›å½’éªŒè¯

        Args:
            threshold_corr: ç›¸å…³ç³»æ•°é˜ˆå€¼
            threshold_vif: VIFé˜ˆå€¼

        Returns:
            {
                'correlation_analysis': [...],
                'vif_analysis': [...],
                'filtered_features': [...],
                'removed_features': [...],
                'execution_time': 30.2
            }
        """
        if self.stage1_results is None:
            raise ValueError("è¯·å…ˆè¿è¡Œé˜¶æ®µ1")

        import time
        start_time = time.time()

        top_features = self.stage1_results['top_features']
        X_subset = self.X[top_features]

        # 1. ç›¸å…³æ€§åˆ†æ
        corr_results = self.validator.compute_correlations(X_subset, self.y)

        # è¿‡æ»¤ä½ç›¸å…³ç‰¹å¾
        features_after_corr = [
            f['feature'] for f in corr_results
            if abs(f['pearson_r']) >= threshold_corr
            or abs(f['spearman_r']) >= threshold_corr
        ]

        # 2. VIFåˆ†æ
        X_after_corr = self.X[features_after_corr]
        vif_results = self.validator.compute_vif(X_after_corr)

        # è¿­ä»£ç§»é™¤é«˜VIFç‰¹å¾
        features_final = self.validator.remove_high_vif_features(
            vif_results, threshold=threshold_vif
        )

        removed_features = list(set(top_features) - set(features_final))

        self.stage2_results = {
            'correlation_analysis': corr_results,
            'vif_analysis': vif_results,
            'filtered_features': features_final,
            'removed_features': removed_features,
            'execution_time': time.time() - start_time
        }

        return self.stage2_results

    def run_stage3_wrapper(self, final_k: int = 10,
                          cv_folds: int = 5) -> Dict:
        """
        é˜¶æ®µ3: Wrapperç²¾é€‰

        Args:
            final_k: æœ€ç»ˆç‰¹å¾æ•°é‡
            cv_folds: äº¤å‰éªŒè¯æŠ˜æ•°

        Returns:
            {
                'rfe_results': {...},
                'lasso_results': {...},
                'rf_results': {...},
                'best_method': 'RFE',
                'final_features': [...],
                'cv_scores': {...},
                'execution_time': 600.5
            }
        """
        if self.stage2_results is None:
            raise ValueError("è¯·å…ˆè¿è¡Œé˜¶æ®µ2")

        import time
        start_time = time.time()

        filtered_features = self.stage2_results['filtered_features']
        X_subset = self.X[filtered_features]

        # 1. RFE + MLP
        rfe_results = self.wrapper.run_rfe(
            X_subset, self.y, n_features=final_k
        )

        # 2. LassoCV
        lasso_results = self.wrapper.run_lasso(
            X_subset, self.y, n_features=final_k
        )

        # 3. Random Forest
        rf_results = self.wrapper.run_random_forest(
            X_subset, self.y, n_features=final_k
        )

        # 4. äº¤å‰éªŒè¯å¯¹æ¯”
        mlp = MLPRegressor(hidden_layer_sizes=(64, 32), max_iter=1000)

        cv_scores = {}
        for method_name, result in [('RFE', rfe_results),
                                     ('Lasso', lasso_results),
                                     ('RF', rf_results)]:
            selected_features = result['selected_features']
            X_selected = self.X[selected_features]

            scores = cross_val_score(
                mlp, X_selected, self.y,
                cv=cv_folds, scoring='r2'
            )

            cv_scores[method_name] = {
                'r2_mean': float(scores.mean()),
                'r2_std': float(scores.std()),
                'r2_scores': scores.tolist()
            }

        # 5. é€‰æ‹©æœ€ä¼˜æ–¹æ³•
        best_method = max(cv_scores.items(), key=lambda x: x[1]['r2_mean'])[0]

        if best_method == 'RFE':
            final_features = rfe_results['selected_features']
        elif best_method == 'Lasso':
            final_features = lasso_results['selected_features']
        else:
            final_features = rf_results['selected_features']

        self.stage3_results = {
            'rfe_results': rfe_results,
            'lasso_results': lasso_results,
            'rf_results': rf_results,
            'best_method': best_method,
            'final_features': final_features,
            'cv_scores': cv_scores,
            'execution_time': time.time() - start_time
        }

        return self.stage3_results

    def generate_report(self) -> Dict:
        """
        ç”Ÿæˆå®Œæ•´æŠ¥å‘Š

        Returns:
            {
                'stage1': {...},
                'stage2': {...},
                'stage3': {...},
                'final_features': [...],
                'comparison_with_baseline': {...}
            }
        """
        if any(r is None for r in [self.stage1_results,
                                    self.stage2_results,
                                    self.stage3_results]):
            raise ValueError("è¯·å…ˆå®Œæˆå…¨éƒ¨ä¸‰ä¸ªé˜¶æ®µ")

        # å¯¹æ¯”baselineï¼ˆå½“å‰ANOVAæ–¹æ³•ï¼‰
        baseline_comparison = self._compare_with_baseline()

        return {
            'stage1_filter': self.stage1_results,
            'stage2_validation': self.stage2_results,
            'stage3_wrapper': self.stage3_results,
            'final_features': self.stage3_results['final_features'],
            'comparison_with_baseline': baseline_comparison,
            'total_execution_time': sum([
                self.stage1_results['execution_time'],
                self.stage2_results['execution_time'],
                self.stage3_results['execution_time']
            ])
        }

    def _compare_with_baseline(self) -> Dict:
        """å¯¹æ¯”å½“å‰ANOVAæ–¹æ³•ï¼ˆbaselineï¼‰"""
        from .sensitivity_analyzer import SensitivityAnalyzer

        # Baseline: ANOVAæ–¹æ³•
        analyzer = SensitivityAnalyzer(
            pd.DataFrame({
                **{f: self.X[f] for f in self.feature_names},
                'group': self.groups,
                'subject_id': range(len(self.X)),
                'task_id': ['q1'] * len(self.X)
            })
        )

        baseline_features = analyzer.get_top_k_features(k=10)

        # äº¤å‰éªŒè¯å¯¹æ¯”
        mlp = MLPRegressor(hidden_layer_sizes=(64, 32), max_iter=1000)

        scores_baseline = cross_val_score(
            mlp, self.X[baseline_features], self.y, cv=5, scoring='r2'
        )

        scores_hybrid = cross_val_score(
            mlp, self.X[self.stage3_results['final_features']],
            self.y, cv=5, scoring='r2'
        )

        return {
            'baseline_method': 'ANOVA',
            'baseline_features': baseline_features,
            'baseline_r2': {
                'mean': float(scores_baseline.mean()),
                'std': float(scores_baseline.std())
            },
            'hybrid_method': self.stage3_results['best_method'],
            'hybrid_features': self.stage3_results['final_features'],
            'hybrid_r2': {
                'mean': float(scores_hybrid.mean()),
                'std': float(scores_hybrid.std())
            },
            'improvement': {
                'absolute': float(scores_hybrid.mean() - scores_baseline.mean()),
                'relative_pct': float((scores_hybrid.mean() - scores_baseline.mean())
                                     / scores_baseline.mean() * 100)
            }
        }
```

---

#### **4.2.2 FilterMethodsï¼ˆFilteræ–¹æ³•é›†åˆï¼‰**

```python
# filter_methods.py

import numpy as np
import pandas as pd
from scipy.stats import f_oneway, rankdata
from sklearn.feature_selection import f_regression, mutual_info_regression
from typing import Dict, List


class FilterMethods:
    """Filterç‰¹å¾é€‰æ‹©æ–¹æ³•é›†åˆ"""

    def __init__(self, X: pd.DataFrame, y: pd.Series,
                 feature_names: List[str], groups: pd.Series = None):
        self.X = X
        self.y = y
        self.feature_names = feature_names
        self.groups = groups

    def compute_anova_scores(self) -> np.ndarray:
        """
        è®¡ç®—ANOVAæ•æ„Ÿåº¦å¾—åˆ†

        Returns:
            scores: (n_features,) æ¯ä¸ªç‰¹å¾çš„å¾—åˆ†
        """
        from .sensitivity_analyzer import SensitivityAnalyzer

        # æ„é€ é€‚åˆSensitivityAnalyzerçš„æ•°æ®æ ¼å¼
        df = pd.DataFrame(self.X, columns=self.feature_names)
        df['group'] = self.groups
        df['subject_id'] = range(len(self.X))
        df['task_id'] = ['q1'] * len(self.X)

        analyzer = SensitivityAnalyzer(df)
        results = analyzer.compute_all_features()

        # è¿”å›sensitivity_score
        scores = results['sensitivity_score'].values
        return scores

    def compute_f_regression_scores(self) -> np.ndarray:
        """
        è®¡ç®—F-regressionå¾—åˆ†ï¼ˆé’ˆå¯¹å›å½’ä»»åŠ¡ï¼‰

        Returns:
            scores: (n_features,)
        """
        f_scores, p_values = f_regression(self.X, self.y)

        # ç»“åˆFå€¼å’Œpå€¼
        # Score = F / (1 + p)
        scores = f_scores / (1 + p_values)

        return scores

    def compute_mutual_info_scores(self, random_state: int = 42) -> np.ndarray:
        """
        è®¡ç®—äº’ä¿¡æ¯å¾—åˆ†ï¼ˆå¯æ•æ‰éçº¿æ€§å…³ç³»ï¼‰

        Returns:
            scores: (n_features,)
        """
        mi_scores = mutual_info_regression(
            self.X, self.y,
            random_state=random_state,
            n_neighbors=5
        )

        return mi_scores

    def combine_ranks(self, *score_arrays) -> np.ndarray:
        """
        Borda CountæŠ•ç¥¨

        Args:
            score_arrays: å¤šä¸ªå¾—åˆ†æ•°ç»„

        Returns:
            combined_ranks: (n_features,) ç»¼åˆæ’åï¼ˆè¶Šå°è¶Šå¥½ï¼‰
        """
        ranks = []
        for scores in score_arrays:
            # å¾—åˆ†è¶Šé«˜æ’åè¶Šå°ï¼ˆ1, 2, 3, ...ï¼‰
            rank = rankdata(-scores, method='average')
            ranks.append(rank)

        # æ’åæ±‚å’Œï¼ˆBorda Countï¼‰
        combined_ranks = np.sum(ranks, axis=0)

        return combined_ranks
```

---

#### **4.2.3 WrapperMethodsï¼ˆWrapperæ–¹æ³•é›†åˆï¼‰**

```python
# wrapper_methods.py

import numpy as np
import pandas as pd
from typing import Dict, List
from sklearn.feature_selection import RFE
from sklearn.linear_model import LassoCV
from sklearn.ensemble import RandomForestRegressor
from sklearn.neural_network import MLPRegressor


class WrapperMethods:
    """Wrapperç‰¹å¾é€‰æ‹©æ–¹æ³•é›†åˆ"""

    def __init__(self, X: pd.DataFrame, y: pd.Series, feature_names: List[str]):
        self.X = X
        self.y = y
        self.feature_names = feature_names

    def run_rfe(self, X_subset: pd.DataFrame, y: pd.Series,
                n_features: int = 10) -> Dict:
        """
        é€’å½’ç‰¹å¾æ¶ˆé™¤ (RFE) + MLP

        Returns:
            {
                'method': 'RFE',
                'selected_features': [...],
                'feature_ranking': [...],
                'execution_time': 120.5
            }
        """
        import time
        start_time = time.time()

        mlp = MLPRegressor(
            hidden_layer_sizes=(64, 32, 16),
            activation='relu',
            max_iter=1000,
            random_state=42,
            early_stopping=True
        )

        rfe = RFE(
            estimator=mlp,
            n_features_to_select=n_features,
            step=1,
            verbose=0
        )

        rfe.fit(X_subset, y)

        selected_indices = rfe.support_
        selected_features = X_subset.columns[selected_indices].tolist()

        return {
            'method': 'RFE',
            'selected_features': selected_features,
            'feature_ranking': rfe.ranking_.tolist(),
            'execution_time': time.time() - start_time
        }

    def run_lasso(self, X_subset: pd.DataFrame, y: pd.Series,
                  n_features: int = 10) -> Dict:
        """
        LassoCV (L1æ­£åˆ™åŒ–)

        Returns:
            {
                'method': 'Lasso',
                'selected_features': [...],
                'coefficients': [...],
                'alpha': 0.05,
                'execution_time': 60.2
            }
        """
        import time
        start_time = time.time()

        lasso = LassoCV(
            cv=5,
            random_state=42,
            max_iter=10000,
            n_alphas=100
        )

        lasso.fit(X_subset, y)

        # é€‰æ‹©ç³»æ•°ç»å¯¹å€¼æœ€å¤§çš„Top-Kç‰¹å¾
        coef_abs = np.abs(lasso.coef_)
        top_indices = np.argsort(coef_abs)[-n_features:]

        selected_features = X_subset.columns[top_indices].tolist()

        return {
            'method': 'Lasso',
            'selected_features': selected_features,
            'coefficients': lasso.coef_.tolist(),
            'alpha': float(lasso.alpha_),
            'execution_time': time.time() - start_time
        }

    def run_random_forest(self, X_subset: pd.DataFrame, y: pd.Series,
                         n_features: int = 10) -> Dict:
        """
        Random Forestç‰¹å¾é‡è¦æ€§

        Returns:
            {
                'method': 'RandomForest',
                'selected_features': [...],
                'feature_importances': [...],
                'execution_time': 45.8
            }
        """
        import time
        start_time = time.time()

        rf = RandomForestRegressor(
            n_estimators=200,
            max_depth=10,
            random_state=42,
            n_jobs=-1
        )

        rf.fit(X_subset, y)

        # é€‰æ‹©é‡è¦æ€§æœ€é«˜çš„Top-Kç‰¹å¾
        importances = rf.feature_importances_
        top_indices = np.argsort(importances)[-n_features:]

        selected_features = X_subset.columns[top_indices].tolist()

        return {
            'method': 'RandomForest',
            'selected_features': selected_features,
            'feature_importances': importances.tolist(),
            'execution_time': time.time() - start_time
        }
```

---

#### **4.2.4 ValidationUtilsï¼ˆéªŒè¯å·¥å…·ï¼‰**

```python
# validation_utils.py

import numpy as np
import pandas as pd
from scipy.stats import pearsonr, spearmanr
from statsmodels.stats.outliers_influence import variance_inflation_factor
from typing import Dict, List


class ValidationUtils:
    """ç‰¹å¾éªŒè¯å·¥å…·"""

    def __init__(self, X: pd.DataFrame, y: pd.Series, feature_names: List[str]):
        self.X = X
        self.y = y
        self.feature_names = feature_names

    def compute_correlations(self, X_subset: pd.DataFrame,
                            y: pd.Series) -> List[Dict]:
        """
        è®¡ç®—ç‰¹å¾ä¸ç›®æ ‡çš„ç›¸å…³ç³»æ•°

        Returns:
            [
                {
                    'feature': 'total_saccades',
                    'pearson_r': 0.45,
                    'pearson_p': 0.001,
                    'spearman_r': 0.42,
                    'spearman_p': 0.002
                },
                ...
            ]
        """
        results = []

        for feature in X_subset.columns:
            r_pearson, p_pearson = pearsonr(X_subset[feature], y)
            r_spearman, p_spearman = spearmanr(X_subset[feature], y)

            results.append({
                'feature': feature,
                'pearson_r': float(r_pearson),
                'pearson_p': float(p_pearson),
                'spearman_r': float(r_spearman),
                'spearman_p': float(p_spearman)
            })

        # æŒ‰Pearsonç›¸å…³ç³»æ•°ç»å¯¹å€¼é™åºæ’åº
        results.sort(key=lambda x: abs(x['pearson_r']), reverse=True)

        return results

    def compute_vif(self, X_subset: pd.DataFrame) -> List[Dict]:
        """
        è®¡ç®—æ–¹å·®è†¨èƒ€å› å­ï¼ˆVIFï¼‰

        Returns:
            [
                {'feature': 'total_saccades', 'vif': 2.3},
                {'feature': 'total_fixations', 'vif': 4.8},
                ...
            ]
        """
        vif_data = []

        for i, feature in enumerate(X_subset.columns):
            vif_value = variance_inflation_factor(X_subset.values, i)
            vif_data.append({
                'feature': feature,
                'vif': float(vif_value)
            })

        # æŒ‰VIFé™åºæ’åº
        vif_data.sort(key=lambda x: x['vif'], reverse=True)

        return vif_data

    def remove_high_vif_features(self, vif_results: List[Dict],
                                 threshold: float = 5.0) -> List[str]:
        """
        è¿­ä»£ç§»é™¤é«˜VIFç‰¹å¾

        ç®—æ³•ï¼š
        1. æ‰¾åˆ°VIFæœ€é«˜çš„ç‰¹å¾
        2. å¦‚æœVIF > thresholdï¼Œç§»é™¤è¯¥ç‰¹å¾
        3. é‡æ–°è®¡ç®—å‰©ä½™ç‰¹å¾çš„VIF
        4. é‡å¤ç›´åˆ°æ‰€æœ‰VIF < threshold

        Returns:
            filtered_features: è¿‡æ»¤åçš„ç‰¹å¾åˆ—è¡¨
        """
        current_features = [item['feature'] for item in vif_results]

        while True:
            X_current = self.X[current_features]
            vif_current = self.compute_vif(X_current)

            max_vif_item = max(vif_current, key=lambda x: x['vif'])

            if max_vif_item['vif'] < threshold:
                break

            # ç§»é™¤VIFæœ€é«˜çš„ç‰¹å¾
            current_features.remove(max_vif_item['feature'])

            if len(current_features) <= 1:
                break

        return current_features
```

---

### 4.3 æ‰©å±•Serviceå±‚

```python
# service.py (æ‰©å±•ç°æœ‰ç±»)

class FeatureExtractionService:
    # ... ç°æœ‰ä»£ç  ...

    def compute_hybrid_selection(self, data_version: str = 'v1',
                                 mode: str = 'fast') -> Dict:
        """
        æ··åˆç‰¹å¾é€‰æ‹©ï¼ˆæ–¹æ¡ˆCï¼‰

        Args:
            data_version: æ•°æ®ç‰ˆæœ¬
            mode: 'fast'ï¼ˆä»…é˜¶æ®µ1+2ï¼‰æˆ– 'precise'ï¼ˆå…¨éƒ¨ä¸‰é˜¶æ®µï¼‰

        Returns:
            å®Œæ•´æŠ¥å‘Š
        """
        logger.info(f"å¼€å§‹æ··åˆç‰¹å¾é€‰æ‹© (mode={mode})")

        # 1. åŠ è½½æ‰€æœ‰å€™é€‰ç‰¹å¾
        X, y, groups, feature_names = self._load_all_features(data_version)

        # 2. åˆå§‹åŒ–æ··åˆé€‰æ‹©å™¨
        from .hybrid_selector import HybridFeatureSelector

        selector = HybridFeatureSelector(X, y, feature_names, groups)

        # 3. è¿è¡Œé˜¶æ®µ1
        stage1_results = selector.run_stage1_filter(top_k=15)
        logger.info(f"é˜¶æ®µ1å®Œæˆ: {len(stage1_results['top_features'])} å€™é€‰ç‰¹å¾")

        # 4. è¿è¡Œé˜¶æ®µ2
        stage2_results = selector.run_stage2_validation(
            threshold_corr=0.25,
            threshold_vif=5.0
        )
        logger.info(f"é˜¶æ®µ2å®Œæˆ: {len(stage2_results['filtered_features'])} ç‰¹å¾é€šè¿‡éªŒè¯")

        # 5. æ ¹æ®modeå†³å®šæ˜¯å¦è¿è¡Œé˜¶æ®µ3
        if mode == 'precise':
            stage3_results = selector.run_stage3_wrapper(final_k=10, cv_folds=5)
            logger.info(f"é˜¶æ®µ3å®Œæˆ: æœ€ä¼˜æ–¹æ³• = {stage3_results['best_method']}")
        else:
            stage3_results = None
            logger.info("å¿«é€Ÿæ¨¡å¼: è·³è¿‡é˜¶æ®µ3")

        # 6. ç”ŸæˆæŠ¥å‘Š
        report = selector.generate_report() if mode == 'precise' else {
            'stage1_filter': stage1_results,
            'stage2_validation': stage2_results,
            'mode': 'fast',
            'note': 'å¿«é€Ÿæ¨¡å¼ä»…å®ŒæˆFilterå’ŒéªŒè¯ï¼Œå»ºè®®è¿è¡Œç²¾ç¡®æ¨¡å¼è·å¾—æœ€ä¼˜ç‰¹å¾'
        }

        # 7. ç¼“å­˜ç»“æœ
        cache_file = self.cache_dir / f'hybrid_selection_{mode}_{data_version}.json'
        with open(cache_file, 'w', encoding='utf-8') as f:
            import json
            json.dump(report, f, ensure_ascii=False, indent=2)

        return report

    def _load_all_features(self, data_version: str) -> Tuple:
        """
        åŠ è½½æ‰€æœ‰å€™é€‰ç‰¹å¾

        Returns:
            (X, y, groups, feature_names)
        """
        # Module04ç‰¹å¾
        m04_features = self._load_m04_features(
            data_version=data_version,
            groups=['control', 'mci', 'ad'],
            velocity_threshold=40.0,
            min_fixation_duration=100
        )

        # Module05ç‰¹å¾ï¼ˆå‡è®¾å·²é¢„è®¡ç®—ï¼‰
        m05_file = self.base_dir / f"data/05_rqa_analysis/results/m1_tau1_eps0.051_lmin2/step3_feature_enrichment/enriched_features.csv"
        m05_features = pd.read_csv(m05_file)
        m05_features.columns = m05_features.columns.str.lower()

        # åˆå¹¶ï¼ˆæŒ‰subject_idï¼‰
        merged = m04_features.merge(
            m05_features,
            on=['subject_id', 'group'],
            how='inner'
        )

        # æå–ç‰¹å¾çŸ©é˜µå’Œç›®æ ‡
        feature_cols = [c for c in merged.columns
                       if c not in ['subject_id', 'group', 'task_id']
                       and 'mmse' not in c.lower()]

        X = merged[feature_cols]
        y = merged['mmse_total_score']  # å‡è®¾å·²åŠ è½½MMSE
        groups = merged['group']

        return X, y, groups, feature_cols
```

---

### 4.4 æ‰©å±•APIè·¯ç”±

```python
# api.py (æ‰©å±•)

from flask import Blueprint, request, jsonify

m06_bp = Blueprint('module06', __name__, url_prefix='/api/m06')


@m06_bp.route('/hybrid/run', methods=['POST'])
def run_hybrid_selection():
    """
    è¿è¡Œæ··åˆç‰¹å¾é€‰æ‹©

    Request Body:
    {
        "data_version": "v1",
        "mode": "fast" | "precise"
    }

    Response:
    {
        "success": true,
        "data": {
            "stage1_filter": {...},
            "stage2_validation": {...},
            "stage3_wrapper": {...},  // ä»…preciseæ¨¡å¼
            "final_features": [...],
            "comparison_with_baseline": {...}
        }
    }
    """
    try:
        data = request.get_json()
        data_version = data.get('data_version', 'v1')
        mode = data.get('mode', 'fast')

        if mode not in ['fast', 'precise']:
            return jsonify({
                'success': False,
                'error': "modeå¿…é¡»æ˜¯'fast'æˆ–'precise'"
            }), 400

        service = FeatureExtractionService()
        report = service.compute_hybrid_selection(
            data_version=data_version,
            mode=mode
        )

        return jsonify({
            'success': True,
            'data': report
        })

    except Exception as e:
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500


@m06_bp.route('/hybrid/compare', methods=['GET'])
def compare_methods():
    """
    å¯¹æ¯”ä¸åŒç‰¹å¾é€‰æ‹©æ–¹æ³•

    Query Params:
    - data_version: v1/v2

    Response:
    {
        "success": true,
        "data": {
            "anova": {
                "features": [...],
                "r2_mean": 0.65,
                "r2_std": 0.08
            },
            "f_regression": {...},
            "mutual_info": {...},
            "hybrid": {...}
        }
    }
    """
    # å®ç°å¯¹æ¯”é€»è¾‘
    pass


@m06_bp.route('/hybrid/visualization', methods=['GET'])
def get_visualization_data():
    """
    è·å–å¯è§†åŒ–æ•°æ®

    Response:
    {
        "success": true,
        "data": {
            "feature_importance_comparison": [...],
            "correlation_heatmap": [...],
            "cv_scores_boxplot": [...]
        }
    }
    """
    # è¿”å›å‰ç«¯ç»˜å›¾æ‰€éœ€æ•°æ®
    pass
```

---

## 5. å‰ç«¯è®¾è®¡

### 5.1 æ–°å¢ç»„ä»¶ç»“æ„

```
frontend/src/components/Module06/
â”œâ”€â”€ HybridSelectionPanel.jsx          # æ··åˆé€‰æ‹©ä¸»é¢æ¿ï¼ˆæ–°å¢ï¼‰
â”œâ”€â”€ Stage1FilterView.jsx              # é˜¶æ®µ1å¯è§†åŒ–ï¼ˆæ–°å¢ï¼‰
â”œâ”€â”€ Stage2ValidationView.jsx          # é˜¶æ®µ2å¯è§†åŒ–ï¼ˆæ–°å¢ï¼‰
â”œâ”€â”€ Stage3WrapperView.jsx             # é˜¶æ®µ3å¯è§†åŒ–ï¼ˆæ–°å¢ï¼‰
â”œâ”€â”€ ComparisonView.jsx                # æ–¹æ³•å¯¹æ¯”è§†å›¾ï¼ˆæ–°å¢ï¼‰
â”œâ”€â”€ FeatureImportanceChart.jsx        # ç‰¹å¾é‡è¦æ€§å›¾è¡¨ï¼ˆæ–°å¢ï¼‰
â””â”€â”€ ProgressTimeline.jsx              # è¿›åº¦æ—¶é—´çº¿ï¼ˆæ–°å¢ï¼‰
```

---

### 5.2 ä¸»é¢æ¿UIè®¾è®¡

#### **HybridSelectionPanel.jsx**

```jsx
import React, { useState } from 'react';
import { Card, Steps, Button, Select, Space, Alert, Spin, Tabs } from 'antd';
import { PlayCircleOutlined, ExperimentOutlined, CompareOutlined } from '@ant-design/icons';
import axios from 'axios';

import Stage1FilterView from './Stage1FilterView';
import Stage2ValidationView from './Stage2ValidationView';
import Stage3WrapperView from './Stage3WrapperView';
import ComparisonView from './ComparisonView';

const { Step } = Steps;
const { Option } = Select;
const { TabPane } = Tabs;

const HybridSelectionPanel = () => {
  const [mode, setMode] = useState('fast'); // 'fast' | 'precise'
  const [dataVersion, setDataVersion] = useState('v1');
  const [loading, setLoading] = useState(false);
  const [currentStep, setCurrentStep] = useState(0);
  const [results, setResults] = useState(null);

  const handleRunAnalysis = async () => {
    setLoading(true);
    setCurrentStep(0);

    try {
      const response = await axios.post('http://127.0.0.1:9090/api/m06/hybrid/run', {
        data_version: dataVersion,
        mode: mode
      });

      if (response.data.success) {
        setResults(response.data.data);
        setCurrentStep(mode === 'precise' ? 3 : 2);
        message.success(`${mode === 'precise' ? 'ç²¾ç¡®' : 'å¿«é€Ÿ'}æ¨¡å¼åˆ†æå®Œæˆï¼`);
      }
    } catch (error) {
      message.error('åˆ†æå¤±è´¥: ' + error.message);
    } finally {
      setLoading(false);
    }
  };

  return (
    <Space direction="vertical" size="large" style={{ width: '100%' }}>
      {/* æ§åˆ¶é¢æ¿ */}
      <Card title="æ··åˆç‰¹å¾é€‰æ‹©ï¼ˆæ–¹æ¡ˆCï¼‰">
        <Space size="large">
          <div>
            <label>æ•°æ®ç‰ˆæœ¬: </label>
            <Select value={dataVersion} onChange={setDataVersion} style={{ width: 100 }}>
              <Option value="v1">V1</Option>
              <Option value="v2">V2</Option>
            </Select>
          </div>

          <div>
            <label>æ¨¡å¼: </label>
            <Select value={mode} onChange={setMode} style={{ width: 150 }}>
              <Option value="fast">å¿«é€Ÿæ¨¡å¼ (~2åˆ†é’Ÿ)</Option>
              <Option value="precise">ç²¾ç¡®æ¨¡å¼ (~10åˆ†é’Ÿ)</Option>
            </Select>
          </div>

          <Button
            type="primary"
            icon={<ExperimentOutlined />}
            onClick={handleRunAnalysis}
            loading={loading}
            size="large"
          >
            è¿è¡Œåˆ†æ
          </Button>
        </Space>

        <Alert
          message={mode === 'fast'
            ? 'å¿«é€Ÿæ¨¡å¼ï¼šä»…è¿è¡Œé˜¶æ®µ1ï¼ˆFilterï¼‰å’Œé˜¶æ®µ2ï¼ˆéªŒè¯ï¼‰ï¼Œé€‚åˆåˆæ­¥æ¢ç´¢'
            : 'ç²¾ç¡®æ¨¡å¼ï¼šå®Œæ•´è¿è¡Œä¸‰é˜¶æ®µï¼Œä½¿ç”¨äº¤å‰éªŒè¯é€‰å‡ºæœ€ä¼˜ç‰¹å¾å­é›†'}
          type="info"
          showIcon
          style={{ marginTop: 16 }}
        />
      </Card>

      {/* è¿›åº¦æŒ‡ç¤º */}
      {loading && (
        <Card>
          <Steps current={currentStep}>
            <Step title="é˜¶æ®µ1: Filteré¢„ç­›é€‰" description="ANOVA + F-regression + MI" />
            <Step title="é˜¶æ®µ2: å›å½’éªŒè¯" description="ç›¸å…³æ€§ + VIF" />
            <Step title="é˜¶æ®µ3: Wrapperç²¾é€‰" description="RFE + Lasso + RF" />
          </Steps>
          <div style={{ textAlign: 'center', marginTop: 24 }}>
            <Spin size="large" tip={`æ­£åœ¨æ‰§è¡Œ${['é˜¶æ®µ1', 'é˜¶æ®µ2', 'é˜¶æ®µ3'][currentStep]}...`} />
          </div>
        </Card>
      )}

      {/* ç»“æœå±•ç¤º */}
      {results && !loading && (
        <Tabs defaultActiveKey="stages" size="large">
          <TabPane tab="ğŸ“Š åˆ†é˜¶æ®µç»“æœ" key="stages">
            <Space direction="vertical" size="large" style={{ width: '100%' }}>
              <Stage1FilterView data={results.stage1_filter} />
              <Stage2ValidationView data={results.stage2_validation} />
              {mode === 'precise' && (
                <Stage3WrapperView data={results.stage3_wrapper} />
              )}
            </Space>
          </TabPane>

          <TabPane tab="ğŸ”¬ æ–¹æ³•å¯¹æ¯”" key="comparison">
            <ComparisonView data={results.comparison_with_baseline} />
          </TabPane>

          <TabPane tab="âœ… æœ€ç»ˆç‰¹å¾" key="final">
            <Card title="æœ€ç»ˆé€‰å‡ºçš„10ä¸ªç‰¹å¾">
              <FinalFeaturesTable
                features={results.final_features}
                method={results.stage3_wrapper?.best_method || 'Stage2'}
              />
            </Card>
          </TabPane>
        </Tabs>
      )}
    </Space>
  );
};

export default HybridSelectionPanel;
```

---

### 5.3 é˜¶æ®µè§†å›¾ç»„ä»¶

#### **Stage1FilterView.jsx**

```jsx
import React from 'react';
import { Card, Table, Row, Col, Statistic } from 'antd';
import { Bar } from '@ant-design/charts';

const Stage1FilterView = ({ data }) => {
  if (!data) return null;

  // å‡†å¤‡æŸ±çŠ¶å›¾æ•°æ®
  const chartData = data.top_features.map((feature, index) => ({
    feature: feature,
    ANOVA: data.anova_scores[index],
    'F-regression': data.freg_scores[index],
    'Mutual Info': data.mi_scores[index]
  })).flatMap(item => [
    { feature: item.feature, method: 'ANOVA', score: item.ANOVA },
    { feature: item.feature, method: 'F-regression', score: item['F-regression'] },
    { feature: item.feature, method: 'Mutual Info', score: item['Mutual Info'] }
  ]);

  const config = {
    data: chartData,
    xField: 'score',
    yField: 'feature',
    seriesField: 'method',
    isGroup: true,
    legend: { position: 'top-right' }
  };

  return (
    <Card title="ğŸ” é˜¶æ®µ1: Filteré¢„ç­›é€‰ç»“æœ">
      <Row gutter={16}>
        <Col span={8}>
          <Statistic title="å€™é€‰ç‰¹å¾æ•°" value={27} />
        </Col>
        <Col span={8}>
          <Statistic title="ç­›é€‰å‡ºç‰¹å¾æ•°" value={data.top_features.length} />
        </Col>
        <Col span={8}>
          <Statistic title="æ‰§è¡Œæ—¶é—´" value={data.execution_time.toFixed(1)} suffix="ç§’" />
        </Col>
      </Row>

      <div style={{ marginTop: 24 }}>
        <h4>ä¸‰ç§æ–¹æ³•å¾—åˆ†å¯¹æ¯”</h4>
        <Bar {...config} />
      </div>
    </Card>
  );
};

export default Stage1FilterView;
```

#### **Stage2ValidationView.jsx**

```jsx
import React from 'react';
import { Card, Table, Tag, Tooltip } from 'antd';
import { CheckCircleOutlined, CloseCircleOutlined } from '@ant-design/icons';

const Stage2ValidationView = ({ data }) => {
  if (!data) return null;

  const columns = [
    {
      title: 'ç‰¹å¾åç§°',
      dataIndex: 'feature',
      key: 'feature',
      fixed: 'left'
    },
    {
      title: 'Pearson r',
      dataIndex: 'pearson_r',
      key: 'pearson_r',
      render: (val) => {
        const color = Math.abs(val) >= 0.5 ? 'green' : Math.abs(val) >= 0.3 ? 'orange' : 'red';
        return <Tag color={color}>{val.toFixed(3)}</Tag>;
      },
      sorter: (a, b) => Math.abs(b.pearson_r) - Math.abs(a.pearson_r)
    },
    {
      title: 'Spearman r',
      dataIndex: 'spearman_r',
      key: 'spearman_r',
      render: (val) => val.toFixed(3)
    },
    {
      title: 'VIF',
      dataIndex: 'vif',
      key: 'vif',
      render: (val, record) => {
        const vif = data.vif_analysis.find(v => v.feature === record.feature)?.vif || 0;
        const color = vif < 5 ? 'green' : vif < 10 ? 'orange' : 'red';
        return <Tag color={color}>{vif.toFixed(2)}</Tag>;
      }
    },
    {
      title: 'é€šè¿‡éªŒè¯',
      key: 'passed',
      render: (_, record) => {
        const passed = data.filtered_features.includes(record.feature);
        return passed ?
          <CheckCircleOutlined style={{ color: 'green', fontSize: 20 }} /> :
          <CloseCircleOutlined style={{ color: 'red', fontSize: 20 }} />;
      }
    }
  ];

  const tableData = data.correlation_analysis;

  return (
    <Card title="âœ… é˜¶æ®µ2: å›å½’éªŒè¯ç»“æœ">
      <div style={{ marginBottom: 16 }}>
        <Tag color="green">é€šè¿‡: {data.filtered_features.length}</Tag>
        <Tag color="red">ç§»é™¤: {data.removed_features.length}</Tag>
        <span style={{ marginLeft: 16, color: '#888' }}>
          ç§»é™¤åŸå› ï¼šä½ç›¸å…³æ€§ï¼ˆ|r| < 0.25ï¼‰æˆ–é«˜å…±çº¿æ€§ï¼ˆVIF > 5ï¼‰
        </span>
      </div>

      <Table
        columns={columns}
        dataSource={tableData}
        rowKey="feature"
        pagination={{ pageSize: 15 }}
        scroll={{ x: 1000 }}
      />
    </Card>
  );
};

export default Stage2ValidationView;
```

#### **Stage3WrapperView.jsx**

```jsx
import React from 'react';
import { Card, Table, Row, Col, Statistic, Badge } from 'antd';
import { Column } from '@ant-design/charts';

const Stage3WrapperView = ({ data }) => {
  if (!data) return null;

  // äº¤å‰éªŒè¯å¾—åˆ†å¯¹æ¯”
  const cvData = Object.entries(data.cv_scores).map(([method, scores]) => ({
    method: method,
    r2: scores.r2_mean
  }));

  const chartConfig = {
    data: cvData,
    xField: 'method',
    yField: 'r2',
    label: {
      position: 'top',
      formatter: (datum) => `RÂ² = ${datum.r2.toFixed(3)}`
    },
    columnStyle: {
      fill: ({ method }) => {
        if (method === data.best_method) return '#52c41a';
        return '#1890ff';
      }
    }
  };

  return (
    <Card title="ğŸ† é˜¶æ®µ3: Wrapperç²¾é€‰ç»“æœ">
      <Row gutter={16}>
        <Col span={6}>
          <Statistic
            title="æœ€ä¼˜æ–¹æ³•"
            value={data.best_method}
            prefix={<Badge status="success" />}
          />
        </Col>
        <Col span={6}>
          <Statistic
            title="æœ€ä¼˜RÂ²"
            value={data.cv_scores[data.best_method].r2_mean.toFixed(3)}
          />
        </Col>
        <Col span={6}>
          <Statistic
            title="æ ‡å‡†å·®"
            value={data.cv_scores[data.best_method].r2_std.toFixed(3)}
          />
        </Col>
        <Col span={6}>
          <Statistic
            title="æ‰§è¡Œæ—¶é—´"
            value={data.execution_time.toFixed(1)}
            suffix="ç§’"
          />
        </Col>
      </Row>

      <div style={{ marginTop: 24 }}>
        <h4>ä¸‰ç§Wrapperæ–¹æ³•æ€§èƒ½å¯¹æ¯”ï¼ˆ5æŠ˜äº¤å‰éªŒè¯ï¼‰</h4>
        <Column {...chartConfig} />
      </div>

      <div style={{ marginTop: 24 }}>
        <h4>æœ€ç»ˆé€‰å‡ºçš„10ä¸ªç‰¹å¾</h4>
        <div>
          {data.final_features.map((f, i) => (
            <Tag key={i} color="green" style={{ margin: 4 }}>{f}</Tag>
          ))}
        </div>
      </div>
    </Card>
  );
};

export default Stage3WrapperView;
```

---

### 5.4 å¯¹æ¯”è§†å›¾

#### **ComparisonView.jsx**

```jsx
import React from 'react';
import { Card, Row, Col, Statistic, Table, Alert } from 'antd';
import { ArrowUpOutlined, ArrowDownOutlined } from '@ant-design/icons';
import { Radar } from '@ant-design/charts';

const ComparisonView = ({ data }) => {
  if (!data) return null;

  const improvement = data.improvement.relative_pct;
  const isImproved = improvement > 0;

  const columns = [
    {
      title: 'æ–¹æ³•',
      dataIndex: 'method',
      key: 'method'
    },
    {
      title: 'é€‰å‡ºçš„ç‰¹å¾',
      dataIndex: 'features',
      key: 'features',
      render: (features) => features.join(', ')
    },
    {
      title: 'RÂ² (å‡å€¼)',
      dataIndex: 'r2_mean',
      key: 'r2_mean',
      sorter: (a, b) => a.r2_mean - b.r2_mean
    },
    {
      title: 'RÂ² (æ ‡å‡†å·®)',
      dataIndex: 'r2_std',
      key: 'r2_std'
    }
  ];

  const tableData = [
    {
      method: 'Baseline (ANOVA)',
      features: data.baseline_features,
      r2_mean: data.baseline_r2.mean.toFixed(3),
      r2_std: data.baseline_r2.std.toFixed(3)
    },
    {
      method: `Hybrid (${data.hybrid_method})`,
      features: data.hybrid_features,
      r2_mean: data.hybrid_r2.mean.toFixed(3),
      r2_std: data.hybrid_r2.std.toFixed(3)
    }
  ];

  return (
    <Card title="ğŸ“ˆ æ–¹æ³•å¯¹æ¯”: Baseline vs Hybrid">
      <Alert
        message={isImproved ? 'æ€§èƒ½æå‡ âœ…' : 'æ€§èƒ½ä¸‹é™ âš ï¸'}
        description={`æ··åˆæ–¹æ³•ç›¸æ¯”Baseline ${isImproved ? 'æå‡' : 'é™ä½'} ${Math.abs(improvement).toFixed(2)}%`}
        type={isImproved ? 'success' : 'warning'}
        showIcon
        style={{ marginBottom: 24 }}
      />

      <Row gutter={16}>
        <Col span={8}>
          <Statistic
            title="Baseline RÂ²"
            value={data.baseline_r2.mean}
            precision={3}
            valueStyle={{ color: '#1890ff' }}
          />
        </Col>
        <Col span={8}>
          <Statistic
            title="Hybrid RÂ²"
            value={data.hybrid_r2.mean}
            precision={3}
            valueStyle={{ color: '#52c41a' }}
          />
        </Col>
        <Col span={8}>
          <Statistic
            title="æ”¹è¿›å¹…åº¦"
            value={Math.abs(improvement)}
            precision={2}
            suffix="%"
            prefix={isImproved ? <ArrowUpOutlined /> : <ArrowDownOutlined />}
            valueStyle={{ color: isImproved ? '#3f8600' : '#cf1322' }}
          />
        </Col>
      </Row>

      <Table
        columns={columns}
        dataSource={tableData}
        rowKey="method"
        pagination={false}
        style={{ marginTop: 24 }}
      />
    </Card>
  );
};

export default ComparisonView;
```

---

## 6. APIæ¥å£è®¾è®¡

### 6.1 å®Œæ•´APIåˆ—è¡¨

| ç«¯ç‚¹ | æ–¹æ³• | æè¿° | é¢„è®¡è€—æ—¶ |
|------|------|------|---------|
| `/api/m06/hybrid/run` | POST | è¿è¡Œæ··åˆç‰¹å¾é€‰æ‹© | 2-10åˆ†é’Ÿ |
| `/api/m06/hybrid/status` | GET | æŸ¥è¯¢ä»»åŠ¡çŠ¶æ€ï¼ˆå¦‚æœå¼‚æ­¥ï¼‰ | <1ç§’ |
| `/api/m06/hybrid/compare` | GET | å¯¹æ¯”ä¸åŒæ–¹æ³• | <5ç§’ |
| `/api/m06/hybrid/visualization` | GET | è·å–å¯è§†åŒ–æ•°æ® | <2ç§’ |
| `/api/m06/hybrid/export` | POST | å¯¼å‡ºç‰¹å¾å­é›† | <5ç§’ |

### 6.2 è¯¦ç»†æ¥å£è§„èŒƒ

è§ä¸Šæ–‡APIè·¯ç”±è®¾è®¡éƒ¨åˆ†ï¼ˆ4.4èŠ‚ï¼‰

---

## 7. æ•°æ®æµç¨‹

```
ç”¨æˆ·æ“ä½œ
   â†“
å‰ç«¯: é€‰æ‹©æ¨¡å¼ï¼ˆfast/preciseï¼‰
   â†“
åç«¯: HybridFeatureSelector.run_stage1_filter()
   â”œâ”€ FilterMethods.compute_anova_scores()
   â”œâ”€ FilterMethods.compute_f_regression_scores()
   â””â”€ FilterMethods.compute_mutual_info_scores()
   â†“
   æŠ•ç¥¨é€‰å‡ºTop-15
   â†“
åç«¯: HybridFeatureSelector.run_stage2_validation()
   â”œâ”€ ValidationUtils.compute_correlations()
   â””â”€ ValidationUtils.compute_vif()
   â†“
   è¿‡æ»¤åˆ°12-13ä¸ªç‰¹å¾
   â†“
åç«¯: HybridFeatureSelector.run_stage3_wrapper() [ä»…preciseæ¨¡å¼]
   â”œâ”€ WrapperMethods.run_rfe()
   â”œâ”€ WrapperMethods.run_lasso()
   â””â”€ WrapperMethods.run_random_forest()
   â†“
   äº¤å‰éªŒè¯é€‰æœ€ä¼˜ â†’ Top-10
   â†“
åç«¯: å¯¹æ¯”Baselineï¼ˆANOVAï¼‰
   â†“
å‰ç«¯: å±•ç¤ºä¸‰é˜¶æ®µç»“æœ + å¯¹æ¯”
   â†“
ç”¨æˆ·: ä¸‹è½½ç‰¹å¾å­é›† / å¯¼å‡ºæŠ¥å‘Š
```

---

## 8. å®æ–½æ­¥éª¤

### ç¬¬1å¤©: åç«¯æ ¸å¿ƒé€»è¾‘
- [ ] å®ç°`FilterMethods`ç±»ï¼ˆ3ç§Filteræ–¹æ³•ï¼‰
- [ ] å®ç°`ValidationUtils`ç±»ï¼ˆç›¸å…³æ€§ + VIFï¼‰
- [ ] å•å…ƒæµ‹è¯•ï¼šéªŒè¯å„æ–¹æ³•è¾“å‡ºæ­£ç¡®æ€§

### ç¬¬2å¤©: Wrapperæ–¹æ³•
- [ ] å®ç°`WrapperMethods`ç±»ï¼ˆRFE + Lasso + RFï¼‰
- [ ] å®ç°äº¤å‰éªŒè¯è¯„ä¼°é€»è¾‘
- [ ] æµ‹è¯•ï¼šç¡®ä¿ç‰¹å¾é€‰æ‹©ç»“æœåˆç†

### ç¬¬3å¤©: é›†æˆHybridSelector
- [ ] å®ç°`HybridFeatureSelector`ä¸»ç±»
- [ ] é›†æˆä¸‰é˜¶æ®µæµç¨‹
- [ ] å®ç°Baselineå¯¹æ¯”é€»è¾‘

### ç¬¬4å¤©: Serviceå’ŒAPIå±‚
- [ ] æ‰©å±•`FeatureExtractionService`
- [ ] æ·»åŠ APIè·¯ç”±
- [ ] æµ‹è¯•APIç«¯åˆ°ç«¯

### ç¬¬5å¤©: å‰ç«¯UI
- [ ] å®ç°`HybridSelectionPanel`ä¸»é¢æ¿
- [ ] å®ç°ä¸‰ä¸ªé˜¶æ®µè§†å›¾ç»„ä»¶
- [ ] å®ç°å¯¹æ¯”è§†å›¾

### ç¬¬6å¤©: å¯è§†åŒ–ä¼˜åŒ–
- [ ] æ·»åŠ ç‰¹å¾é‡è¦æ€§å›¾è¡¨
- [ ] æ·»åŠ ç›¸å…³æ€§çƒ­åŠ›å›¾
- [ ] ä¼˜åŒ–äº¤äº’ä½“éªŒ

### ç¬¬7å¤©: æµ‹è¯•ä¸ä¼˜åŒ–
- [ ] ç«¯åˆ°ç«¯æµ‹è¯•
- [ ] æ€§èƒ½ä¼˜åŒ–ï¼ˆç¼“å­˜ã€å¹¶è¡Œï¼‰
- [ ] æ–‡æ¡£å®Œå–„

---

## 9. æµ‹è¯•éªŒè¯

### 9.1 åŠŸèƒ½æµ‹è¯•

```python
# test_hybrid_selector.py

import pytest
import pandas as pd
import numpy as np
from src.modules.module06_feature_extraction.hybrid_selector import HybridFeatureSelector


def test_stage1_filter():
    """æµ‹è¯•é˜¶æ®µ1: Filteré¢„ç­›é€‰"""
    # æ„é€ æ¨¡æ‹Ÿæ•°æ®
    np.random.seed(42)
    X = pd.DataFrame(np.random.randn(300, 27), columns=[f'feat_{i}' for i in range(27)])
    y = pd.Series(np.random.randint(20, 30, 300))
    groups = pd.Series(['control'] * 100 + ['mci'] * 100 + ['ad'] * 100)

    selector = HybridFeatureSelector(X, y, X.columns.tolist(), groups)
    results = selector.run_stage1_filter(top_k=15)

    assert len(results['top_features']) == 15
    assert 'anova_scores' in results
    assert 'freg_scores' in results
    assert 'mi_scores' in results


def test_stage2_validation():
    """æµ‹è¯•é˜¶æ®µ2: å›å½’éªŒè¯"""
    # ... ç±»ä¼¼æµ‹è¯•é€»è¾‘


def test_stage3_wrapper():
    """æµ‹è¯•é˜¶æ®µ3: Wrapperç²¾é€‰"""
    # ... ç±»ä¼¼æµ‹è¯•é€»è¾‘


def test_end_to_end():
    """ç«¯åˆ°ç«¯æµ‹è¯•"""
    # ä½¿ç”¨çœŸå®æ•°æ®æµ‹è¯•å®Œæ•´æµç¨‹
    pass
```

### 9.2 æ€§èƒ½éªŒè¯

**é¢„æœŸæ‰§è¡Œæ—¶é—´ï¼ˆ300æ ·æœ¬ï¼‰ï¼š**
- é˜¶æ®µ1: 60ç§’
- é˜¶æ®µ2: 30ç§’
- é˜¶æ®µ3: 5-10åˆ†é’Ÿï¼ˆå–å†³äºäº¤å‰éªŒè¯ï¼‰

**æ€»è€—æ—¶ï¼š**
- å¿«é€Ÿæ¨¡å¼: ~2åˆ†é’Ÿ
- ç²¾ç¡®æ¨¡å¼: ~10åˆ†é’Ÿ

---

## 10. é¢„æœŸæ•ˆæœ

### 10.1 æ€§èƒ½æå‡é¢„æœŸ

æ ¹æ®æ–‡çŒ®å’Œç»éªŒï¼Œé¢„æœŸæ··åˆæ–¹æ³•ç›¸æ¯”Baselineçš„æå‡ï¼š

| æŒ‡æ ‡ | Baseline (ANOVA) | Hybrid (é¢„æœŸ) | æå‡ |
|------|-----------------|--------------|------|
| RÂ² | 0.60 - 0.70 | 0.65 - 0.75 | +5-10% |
| MAE | 2.5 - 3.0 | 2.2 - 2.8 | -8-12% |
| ç‰¹å¾å†—ä½™åº¦ | ä¸­ç­‰ | ä½ | âœ… |
| å¯è§£é‡Šæ€§ | é«˜ | ä¸­-é«˜ | âš ï¸ |

### 10.2 å¯è§£é‡Šæ€§æå‡

- âœ… **ä¸‰é˜¶æ®µé€æ˜åº¦**ï¼šæ¯é˜¶æ®µéƒ½æœ‰æ˜ç¡®çš„è¯„ä¼°æŒ‡æ ‡
- âœ… **å¤šæ–¹æ³•å¯¹æ¯”**ï¼šç”¨æˆ·å¯çœ‹åˆ°ä¸åŒæ–¹æ³•çš„ç‰¹å¾é‡è¦æ€§
- âœ… **ç»Ÿè®¡éªŒè¯**ï¼šç›¸å…³æ€§ã€VIFæä¾›é¢å¤–è¯æ®
- âœ… **äº¤å‰éªŒè¯**ï¼šé¿å…è¿‡æ‹Ÿåˆï¼Œç»“æœæ›´å¯é 

---

## 11. æ–‡çŒ®å‚è€ƒ

1. **Guyon & Elisseeff (2003).** *An Introduction to Variable and Feature Selection.* JMLR.
2. **Kohavi & John (1997).** *Wrappers for Feature Selection.* Artificial Intelligence.
3. **Saeys et al. (2007).** *A review of feature selection techniques in bioinformatics.* Bioinformatics.
4. **BolÃ³n-Canedo et al. (2015).** *A review of microarray datasets and applied feature selection methods.* Information Sciences.

---

## 12. é™„å½•ï¼šé…ç½®æ–‡ä»¶ç¤ºä¾‹

```yaml
# config/module06_hybrid.yaml

hybrid_selection:
  stage1_filter:
    methods:
      - anova
      - f_regression
      - mutual_info
    top_k: 15
    voting_strategy: borda_count

  stage2_validation:
    correlation_threshold: 0.25
    vif_threshold: 5.0
    correlation_methods:
      - pearson
      - spearman

  stage3_wrapper:
    methods:
      - rfe
      - lasso
      - random_forest
    final_k: 10
    cv_folds: 5
    mlp_config:
      hidden_layers: [64, 32, 16]
      max_iter: 1000
      early_stopping: true
```

---

**æ–‡æ¡£ç‰ˆæœ¬**: 1.0
**åˆ›å»ºæ—¥æœŸ**: 2025-10-12
**ä½œè€…**: Claude
**çŠ¶æ€**: è®¾è®¡é˜¶æ®µ
